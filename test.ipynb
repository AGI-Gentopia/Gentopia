{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-13T00:30:51.937737272Z",
     "start_time": "2023-06-13T00:30:51.454082421Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from gentopia.prompt.rewoo import ZeroShotPlannerPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI agent who makes step-by-step plans to solve a problem under the help of external tools. \n",
      "For each step, make one plan followed by one tool-call, which will be executed later to retrieve evidence for that step.\n",
      "You should store each evidence into a distinct variable #E1, #E2, #E3 ... that can be referred to in later tool-call inputs.    \n",
      "\n",
      "##Available Tools##\n",
      "Google\n",
      "\n",
      "##Output Format (Replace '<...>')##\n",
      "*Plan1: <describe your plan here>\n",
      "*E1: <ToolName>[<input>]\n",
      "*Plan2: <describe next plan>\n",
      "*E2: <ToolName>[<input, you can use #E1 to represent its expected output>]\n",
      "And so on...\n",
      "  \n",
      "##Your Task##\n",
      "what is 1\n",
      "\n",
      "##Now Begin##\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ZeroShotPlannerPrompt.format(tool_description=\"Google\", task=\"what is 1\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T00:30:51.939792661Z",
     "start_time": "2023-06-13T00:30:51.938404477Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"tool_description\", \"task\"],\n",
    "    template=ZeroShotPlannerPrompt,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T00:22:54.456118921Z",
     "start_time": "2023-06-13T00:22:54.455705703Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an AI agent who makes step-by-step plans to solve a problem under the help of external tools. \n",
      "For each step, make one plan followed by one tool-call, which will be executed later to retrieve evidence for that step.\n",
      "You should store each evidence into a distinct variable #E1, #E2, #E3 ... that can be referred to in later tool-call inputs.    \n",
      "\n",
      "##Available Tools##\n",
      "a hammer\n",
      "\n",
      "##Output Format (Replace '<...>')##\n",
      "*Plan1: <describe your plan here>\n",
      "*E1: <ToolName>[<input>]\n",
      "*Plan2: <describe next plan>\n",
      "*E2: <ToolName>[<input, you can use #E1 to represent its expected output>]\n",
      "And so on...\n",
      "  \n",
      "##Your Task##\n",
      "hammering nails\n",
      "\n",
      "##Now Begin##\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = prompt.format(tool_description=\"a hammer\", task=\"hammering nails\")\n",
    "print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T00:23:06.717886556Z",
     "start_time": "2023-06-13T00:23:06.717279167Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nI want you to act as a naming consultant for new companies.\\nWhat is a good name for a company that makes cars?\\n'"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.format(product=\"cars\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-11T17:45:48.144749391Z",
     "start_time": "2023-06-11T17:45:48.141402093Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "100.0"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rapidfuzz import fuzz\n",
    "fuzz.partial_ratio(\"a hammer\", \"hammer\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T00:35:57.001351089Z",
     "start_time": "2023-06-13T00:35:56.999597809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/billxbf/anaconda3/envs/Gentopia/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.9\n",
      "CUDA SETUP: Detected CUDA version 121\n",
      "CUDA SETUP: Loading binary /home/billxbf/anaconda3/envs/Gentopia/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/billxbf/anaconda3/envs/Gentopia/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /home/billxbf/anaconda3/envs/Gentopia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/home/billxbf/anaconda3/envs/Gentopia/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('@/tmp/.ICE-unix/1747,unix/billxbf'), PosixPath('local/billxbf')}\n",
      "  warn(msg)\n",
      "/home/billxbf/anaconda3/envs/Gentopia/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/etc/xdg/xdg-ubuntu')}\n",
      "  warn(msg)\n",
      "/home/billxbf/anaconda3/envs/Gentopia/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('0'), PosixPath('1')}\n",
      "  warn(msg)\n",
      "/home/billxbf/anaconda3/envs/Gentopia/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69e91272450342bcb53f99792ab75378"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"huggyllama/llama-7b\"\n",
    "adapters_name = 'timdettmers/guanaco-7b'\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    max_memory= {i: '24000MB' for i in range(torch.cuda.device_count())},\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, adapters_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T12:26:05.444861955Z",
     "start_time": "2023-06-15T12:25:21.470098661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chat between a curious human and an artificial intelligence assistant.The assistant gives helpful, detailed, and polite answers to the user's questions.\n",
      "### Human: What is the best way to make a hammer? ### Assistant: The best way to make a hammer depends on the type of hammer you want to make and the materials you have available. Here are some general steps you can follow to make a hammer:\n",
      "\n",
      "1. Gather the materials: The first step is to gather the materials you need to make the hammer. You will need a handle, a head, and a shaft. The type of handle and head you use will depend on the type of hammer you want to make.\n",
      "\n",
      "2. Shape the handle: The handle is the part of the hammer that you will hold. You can use a saw, a drill, or a file to shape the handle to your desired size and shape.\n",
      "\n",
      "3. Attach the head: Once you have shaped the handle, you can attach the head to it. You can use a wrench or a hammer to bang the head into place.\n",
      "\n",
      "4. Sharpen the head: If you are making a hammer for driving nails, you will need to sharpen the head. You can do this by using a file or a grinder to sharpen the head.\n",
      "\n",
      "5. Attach the shaft: The shaft is the part of the hammer that connects the handle to the head. You can use a wrench or a hammer to attach the shaft to the head.\n",
      "\n",
      "6. Finish the hammer: Once you have attached the shaft and the head, you can finish the hammer by sanding it and applying a coat of paint or varnish.\n",
      "\n",
      "These are the general steps you can follow to make a hammer. The exact steps may vary depending on the type of hammer you are making and the materials you have available.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the best way to make a hammer?\"\n",
    "formatted_prompt = (\n",
    "    f\"A chat between a curious human and an artificial intelligence assistant.\"\n",
    "    f\"The assistant gives helpful, detailed, and polite answers to the user's questions.\\n\"\n",
    "    f\"### Human: {prompt} ### Assistant:\"\n",
    ")\n",
    "inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "outputs = model.generate(inputs=inputs.input_ids, max_new_tokens=500)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T12:39:44.859204099Z",
     "start_time": "2023-06-15T12:39:34.430724301Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
