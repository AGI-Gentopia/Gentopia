{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:21:21.036511993Z",
     "start_time": "2023-06-20T01:21:20.974303099Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T03:59:59.486201377Z",
     "start_time": "2023-06-20T03:59:59.444882200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7TKLx36UTXrQW4uhtIuB9YkFFwFkW\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1687224105,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The current weather in Boston is sunny and windy with a temperature of 72 degrees.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 72,\n",
      "    \"completion_tokens\": 17,\n",
      "    \"total_tokens\": 89\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T01:21:46.431617369Z",
     "start_time": "2023-06-20T01:21:28.918627588Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from langchain.tools import GoogleSearchRun\n",
    "from gentopia.tools.google_search import GoogleSearch\n",
    "from gentopia.util.convert_to_openai import format_tool_to_openai_function\n",
    "from gentopia.agent.react import ReactAgent\n",
    "from gentopia.agent.vanilla import VanillaAgent\n",
    "from gentopia.llm.base_llm import BaseLLM\n",
    "from gentopia.model.param_model import BaseParamModel, OpenAIParamModel\n",
    "from gentopia.llm.client.openai import OpenAIGPTClient"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T07:21:34.390274066Z",
     "start_time": "2023-06-21T07:21:34.345455879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'mathira', 'description': 'An mathematical expert that can answer any math problems correctly', 'parameters': {'title': 'ArgsSchema', 'type': 'object', 'properties': {'instruction': {'title': 'Instruction', 'type': 'string'}}, 'required': ['instruction']}}\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"mathira\",\n",
      "    \"arguments\": \"{\\n  \\\"instruction\\\": \\\"square(23)\\\"\\n}\"\n",
      "  }\n",
      "}\n",
      "{'instruction': 'square(23)'}\n",
      "The square of 23 is 529.\n",
      "[{'role': 'user', 'content': \"What's the square of 23?\"}, <OpenAIObject at 0x7f59a47b3ec0> JSON: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"mathira\",\n",
      "    \"arguments\": \"{\\n  \\\"instruction\\\": \\\"square(23)\\\"\\n}\"\n",
      "  }\n",
      "}, {'role': 'function', 'name': 'mathira', 'content': 'The square of 23 is 529.'}, {'role': 'assistant', 'content': 'The square of 23 is 529.'}]\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import json\n",
    "from gentopia.util.convert_to_openai import format_tool_to_openai_function\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "# def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "#     \"\"\"Get the current weather in a given location\"\"\"\n",
    "#     weather_info = {\n",
    "#         \"location\": location,\n",
    "#         \"temperature\": \"72\",\n",
    "#         \"unit\": unit,\n",
    "#         \"forecast\": [\"sunny\", \"windy\"],\n",
    "#     }\n",
    "#     return json.dumps(weather_info)\n",
    "\n",
    "mathria_agent = VanillaAgent(name=\"mathira\", version=\"v1\", description=\"An mathematical expert that can answer any math problems correctly\", target_tasks=[\"math problems\"], llm=OpenAIGPTClient(model_name=\"gpt-4\", params=OpenAIParamModel()))\n",
    "\n",
    "def mathira(instruction):\n",
    "\n",
    "    return mathria_agent.run(instruction).output\n",
    "\n",
    "\n",
    "\n",
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the square of 23?\"}]\n",
    "    func_param = format_tool_to_openai_function(mathria_agent)\n",
    "    print(func_param)\n",
    "    functions = [\n",
    "        func_param\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "        api_key= \"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\"\n",
    "\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    print(response_message)\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"mathira\": mathira,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        print(function_args)\n",
    "        function_response = fuction_to_call(\n",
    "            instruction=function_args.get(\"instruction\"),\n",
    "        )\n",
    "\n",
    "        print(function_response)\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=messages,\n",
    "            api_key=\"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\"\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "        messages.append(dict(second_response[\"choices\"][0][\"message\"]))\n",
    "        return second_response, messages\n",
    "\n",
    "_,msg = run_conversation()\n",
    "print(msg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T07:21:41.210520620Z",
     "start_time": "2023-06-21T07:21:36.233246937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'role': 'user', 'content': \"What's the square of 23?\"},\n {'role': 'function',\n  'name': 'mathira',\n  'content': 'The square of 23 is 529.'},\n <OpenAIObject at 0x7f59a472c630> JSON: {\n   \"role\": \"assistant\",\n   \"content\": \"\"\n }]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T04:48:06.231217966Z",
     "start_time": "2023-06-20T04:48:06.226322115Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'role': 'user', 'content': \"What's the square of 23?\"},\n <OpenAIObject at 0x7f59a47b2a20> JSON: {\n   \"role\": \"assistant\",\n   \"content\": null,\n   \"function_call\": {\n     \"name\": \"mathira\",\n     \"arguments\": \"{\\n  \\\"instruction\\\": \\\"square(23)\\\"\\n}\"\n   }\n },\n {'role': 'function',\n  'name': 'mathira',\n  'content': 'The square of 23 is 529.'},\n {'role': 'assistant', 'content': 'The square of 23 is 529.'}]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T04:50:23.002736726Z",
     "start_time": "2023-06-20T04:50:23.000921587Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "'The square of 23 is 529.'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg[3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-20T04:49:31.722444519Z",
     "start_time": "2023-06-20T04:49:31.679817670Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
